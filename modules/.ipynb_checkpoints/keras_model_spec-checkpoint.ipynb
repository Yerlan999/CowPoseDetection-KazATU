{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d108a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from pathlib import Path\n",
    "import cv2, pickle, csv, os, sys, re\n",
    "from PIL import Image, ImageOps\n",
    "from tools import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, MaxPooling2D, Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
    "from keras import optimizers, regularizers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bb2633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bda5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение таблицы ключевых точек и директории изображении. Указать путь к CSV файлу и изображениям.\n",
    "csv_file_path = Path(r\"C:\\Training_Project300x200(aug)\\Training_Project_dataset.csv\")\n",
    "images_dirname = Path(r\"C:\\Training_Project300x200(aug)\\colored\")\n",
    "\n",
    "# Получения основных данных\n",
    "SHAPE, last_image_index, curr_img_count, current_wd, keypoints_df, sorted_images, images_count_initail_state, csv_initial_state = get_main_data(csv_file_path, images_dirname, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32950d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка. Просмотр заглавления таблицы\n",
    "keypoints_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e00882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Просмотр одного изображения по номеру(индексу)         \n",
    "plot_cow(Path(os.path.join(images_dirname, sorted_images[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c4663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Просмотр изображении с аннотациями по номеру(индексу)\n",
    "show_cowannot(0, keypoints_df, images_dirname, sorted_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caff88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                             !!! УВЕЛИЧЕНИЕ ДАННЫХ !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f37b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Каскад увеличения данных \n",
    "data_augment = [\n",
    "    \n",
    "#     FlipImages(), \n",
    "#     MirrorImages(),\n",
    "#     MirrorFlipImages(),\n",
    "    \n",
    "#     RotateImages(5),\n",
    "#     RotateImages(-5),\n",
    "#     RotateImages(10),\n",
    "#     RotateImages(-10),\n",
    "#     RotateImages(15),\n",
    "#     RotateImages(-15),\n",
    "#     RotateImages(20),\n",
    "#     RotateImages(-20),\n",
    "#     RotateImages(30),\n",
    "#     RotateImages(-30),\n",
    "#     ShiftImages(10, 10),\n",
    "#     ShiftImages(-10, -10),\n",
    "#     ShiftImages(10, -10),\n",
    "#     ShiftImages(-10, 10),   \n",
    "    \n",
    "#     BlurImages(5),\n",
    "#     BlurImages(11),\n",
    "#     NoiseImages(0.3),\n",
    "#     NoiseImages(0.1),\n",
    "#     ContrastImages(1.5),\n",
    "#     ContrastImages(1.1),    \n",
    "#     SaturationImages(1.5),\n",
    "#     BrightenImages(1.5), \n",
    "#     SaturationImages(1.1),\n",
    "#     BrightenImages(1.1), \n",
    "\n",
    "]\n",
    "AugmentApply(data_augment, SHAPE, last_image_index, curr_img_count, current_wd, keypoints_df, sorted_images, images_dirname, csv_file_path, images_count_initail_state, csv_initial_state); SHAPE, last_image_index, curr_img_count, current_wd, keypoints_df, sorted_images = get_main_data(csv_file_path, images_dirname, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9fddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Просмотр изображении с аннотациями по номеру(индексу)\n",
    "show_cowannot(0, keypoints_df, images_dirname, sorted_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                            !!! ЧАСТЬ МАШИННОГО ОБУЧЕНИЯ !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b3b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных\n",
    "if SHAPE[2] == 3:\n",
    "    X = np.stack([string2image(Path(os.path.join(images_dirname, image_path))) for image_path in sorted_images]).astype(np.float64)[:, :, :, :]\n",
    "if SHAPE[2] == 1:\n",
    "    X = np.stack([string2image(Path(os.path.join(images_dirname, image_path))) for image_path in sorted_images]).astype(np.float64)[:, :, :, np.newaxis]\n",
    "\n",
    "y = np.vstack(keypoints_df[keypoints_df.columns[2:]].values)\n",
    "X_train = X / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa9b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных\n",
    "output_pipe = make_pipeline(\n",
    "    MinMaxScaler(feature_range=(-1, 1))\n",
    ")\n",
    "\n",
    "y_train = output_pipe.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee5c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# МОДЕЛЬ МАШИННОГО ОБУЧЕНИЯ\n",
    "model = Sequential()\n",
    "\n",
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "activation_function = 'relu'\n",
    "dropout = 0.5\n",
    "usebias = False\n",
    "leaky_alpha = 0.1\n",
    "\n",
    "filter_size = 64\n",
    "kernel_size = (3, 3)\n",
    "conv_strides = (1, 1)\n",
    "padding = \"same\"\n",
    "\n",
    "pool_strides = (2, 2)\n",
    "pool_size = (2, 2)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Входной слой\n",
    "model.add(BatchNormalization(input_shape=(SHAPE)))\n",
    "model.add(Conv2D(8, kernel_size, kernel_initializer='he_normal', padding=padding, use_bias=usebias, strides=conv_strides))\n",
    "# model.add(Activation(activation_function))\n",
    "model.add(LeakyReLU(alpha = leaky_alpha))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=pool_strides))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "# Второй слой\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(16, kernel_size, padding=padding, use_bias=usebias, strides=conv_strides))\n",
    "# model.add(Activation(activation_function))\n",
    "model.add(LeakyReLU(alpha = leaky_alpha))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=pool_strides))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "# Второй слой\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size, padding=padding, use_bias=usebias, strides=conv_strides))\n",
    "# model.add(Activation(activation_function))\n",
    "model.add(LeakyReLU(alpha = leaky_alpha))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=pool_strides))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "# Второй слой\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size, padding=padding, use_bias=usebias, strides=conv_strides))\n",
    "# model.add(Activation(activation_function))\n",
    "model.add(LeakyReLU(alpha = leaky_alpha))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=pool_strides))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "# Второй слой\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, kernel_size, padding=padding, use_bias=usebias, strides=conv_strides))\n",
    "# model.add(Activation(activation_function))\n",
    "model.add(LeakyReLU(alpha = leaky_alpha))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=pool_strides))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "# Второй слой\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, kernel_size, padding=padding, use_bias=usebias, strides=conv_strides))\n",
    "# model.add(Activation(activation_function))\n",
    "model.add(LeakyReLU(alpha = leaky_alpha))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=pool_strides))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "# Второй слой\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512, kernel_size, padding=padding, use_bias=usebias, strides=conv_strides))\n",
    "# model.add(Activation(activation_function))\n",
    "model.add(LeakyReLU(alpha = leaky_alpha))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=pool_strides))\n",
    "model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(100, kernel_regularizer=regularizers.l2(0.001), activation = activation_function))\n",
    "\n",
    "# model.add(Dense(3072, activation=activation_function))\n",
    "\n",
    "# model.add(Dense(2048, activation=activation_function))\n",
    "\n",
    "model.add(Dense(1024, activation=activation_function))\n",
    "\n",
    "model.add(Dense(512, activation=activation_function))\n",
    "\n",
    "model.add(Dense(128, activation=activation_function))\n",
    "\n",
    "model.add(Dense(64, kernel_regularizer=regularizers.l2(0.001), activation=activation_function))\n",
    "\n",
    "model.add(Dense(128, activation=activation_function))\n",
    "\n",
    "model.add(Dense(512, activation=activation_function))\n",
    "\n",
    "model.add(Dense(1024, activation=activation_function))\n",
    "\n",
    "# model.add(Dense(2048, activation=activation_function))\n",
    "\n",
    "# Восьмой слой\n",
    "model.add(Dense(y.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ffec73",
   "metadata": {},
   "outputs": [],
   "source": [
    " model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe45060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проведение машинного обучения\n",
    "acc = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=50, mode=\"auto\", min_delta=0)\n",
    "val_acc = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=50, mode=\"auto\", min_delta=0)\n",
    "loss = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, mode=\"auto\", min_delta=0)\n",
    "val_loss = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode=\"auto\", min_delta=0)\n",
    "\n",
    "opt = tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.001,\n",
    "    rho=0.9,\n",
    "    momentum=0.0,\n",
    "    epsilon=1e-07,\n",
    "    centered=True,\n",
    "    name=\"RMSprop\")\n",
    "model.compile(optimizer=opt, loss='mse', metrics=['accuracy'])\n",
    "epochs = 300\n",
    "history = model.fit(X_train, y_train, \n",
    "                 validation_split=0.3, shuffle=True, \n",
    "                 epochs=epochs, batch_size=128, callbacks=[acc, val_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17750652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Показать график изменения точности предсказании\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Показать график изменения ошибки предсказании\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c10fce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка предсказании. Вывод данных по номеру(индексу)\n",
    "image_index = 0\n",
    "\n",
    "# Подготовка тестовых данных\n",
    "img = X_train[image_index, :, :, :].reshape(1, *SHAPE)\n",
    "predictions = model.predict(img)\n",
    "\n",
    "# Предсказание модели\n",
    "xy_predictions = output_pipe.inverse_transform(predictions).reshape(y.shape[1]//2, 2)\n",
    "\n",
    "if SHAPE[2] == 3:\n",
    "    plt.imshow(X_train[image_index, :, :, :])\n",
    "if SHAPE[2] == 1:\n",
    "    plt.imshow(X_train[image_index, :, :, :], cmap='gray')\n",
    "\n",
    "lameness = False\n",
    "if xy_predictions[2][1] < xy_predictions[1][1] and xy_predictions[2][1] < xy_predictions[3][1]:\n",
    "    lameness = True\n",
    "    \n",
    "for i, xy in enumerate(xy_predictions):\n",
    "    if lameness and i in [1,2,3]:\n",
    "        plt.plot(xy[0], xy[1], 'r*')\n",
    "    else:\n",
    "        plt.plot(xy[0], xy[1], 'b*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e384527c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "# Для сохранения обученной модели\n",
    "model.save('model')\n",
    "\n",
    "# # Для загрузки ранее сохраненной модели\n",
    "# model = keras.models.load_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392aef41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Для тестирования на отдельных изображениях \n",
    "\n",
    "# Путь к изображению            СЮДА\n",
    "test_image = cv2.imread(\"testdatas/test1.jpg\")\n",
    "\n",
    "reshaped_test_imageI = cv2.resize(test_image, (300, 200))\n",
    "reshaped_test_image = reshaped_test_imageI.reshape(1, *SHAPE)/255\n",
    "predictions = model.predict(reshaped_test_image)\n",
    "xy_predictions = output_pipe.inverse_transform(predictions).reshape(y.shape[1]//2, 2)\n",
    "plt.imshow(reshaped_test_imageI)\n",
    "\n",
    "\n",
    "lameness = False\n",
    "if xy_predictions[2][1] < xy_predictions[1][1] and xy_predictions[2][1] < xy_predictions[3][1]:\n",
    "    lameness = True\n",
    "    \n",
    "for i, xy in enumerate(xy_predictions):\n",
    "    if lameness and i in [1,2,3]:\n",
    "        plt.plot(xy[0], xy[1], 'r*')\n",
    "    else:\n",
    "        plt.plot(xy[0], xy[1], 'b*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b4d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для тестирования на видеоизображениях + произведение записи\n",
    "\n",
    "# Путь к видеофайлу       СЮДА\n",
    "cap = cv2.VideoCapture('testdatas/cow.mp4')\n",
    "\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Ошибка!\")\n",
    "\n",
    "out = cv2.VideoWriter('outputVideo.mp4', cv2.VideoWriter_fourcc(*'DIVX'), 20, (300, 200))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "  # Чтение видео файла кадр за кадром\n",
    "  ret, frame = cap.read()\n",
    "  if ret == True:\n",
    "\n",
    "    # Обработка кадров через модель МО\n",
    "    reshaped_test_imageI = cv2.resize(frame, (300,200))\n",
    "    reshaped_test_image = reshaped_test_imageI.reshape(1, *SHAPE)/255\n",
    "    predictions = model.predict(reshaped_test_image)\n",
    "    xy_predictions = output_pipe.inverse_transform(predictions).reshape(y.shape[1]//2, 2)\n",
    "    \n",
    "    lameness = False\n",
    "    if xy_predictions[2][1] < xy_predictions[1][1] and xy_predictions[2][1] < xy_predictions[3][1]:\n",
    "        lameness = True\n",
    "        \n",
    "    for i, key_point in enumerate(xy_predictions):\n",
    "        if lameness and i in [1,2,3]:\n",
    "            cv2.drawMarker(reshaped_test_imageI, (int(key_point[0]), int(key_point[1])),(0,0,255), markerType=cv2.MARKER_STAR, \n",
    "            markerSize=5, thickness=2, line_type=cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.drawMarker(reshaped_test_imageI, (int(key_point[0]), int(key_point[1])),(255,0,0), markerType=cv2.MARKER_STAR, \n",
    "            markerSize=5, thickness=2, line_type=cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('Frame', reshaped_test_imageI)\n",
    "    out.write(reshaped_test_imageI)\n",
    "  \n",
    "    # Нажми \"Q\" (НА АНГЛИЙСКОЙ РАСКЛАДКЕ КЛАВИАТУРЫ!) чтоб закрыть окно воспроизведения видео\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "      break\n",
    "    \n",
    "  else: \n",
    "    break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2f893a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
